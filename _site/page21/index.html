<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Literature Geek &middot; smarter online communities via digital humanities
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/lanyon.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  <!-- Google Analytics -->
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-6075782-3', 'auto');
  ga('send', 'pageview');
  </script>

</head>

  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">

<div class="sidebar-nav-item">
<form role="search" method="get" action="/search/">
  <input id="searchString" name="searchString"
  placeholder="Search the site" type="text">
  <input id="searchButton" name="googleSearchName" type="submit" value="&#xf002;">
</form>
</div>
 
<nav><a class="sidebar-nav-item" href="http://www.literaturegeek.com"><i class="fa fa-home"></i>
Home</a></nav>
 
<nav><a class="sidebar-nav-item" href="http://www.AmandaVisconti.com"><i class="fa fa-star"></i>
About Amanda Visconti</a></nav>

<nav><a class="sidebar-nav-item" href="mailto:amandavisconti@gmail.com?Subject=ContactFromLiteratureGeekBlog"><i class="fa fa-envelope"></i>
Contact</a></nav>

<nav><a class="sidebar-nav-item" href="http://amandavisconti.com/AmandaVisconti_Resume.pdf"><i class="fa fa-download"></i>
 Download resume</a></nav>

<nav><a class="sidebar-nav-item" href="/tags"><i class="fa fa-tag"></i>
 Posts by topic & date</a></nav>
 
<nav><a class="sidebar-nav-item" href="/speaking"><i class="fa fa-eye"></i> Invited speaking</a></nav>

<nav><a class="sidebar-nav-item" href="http://Dr.AmandaVisconti.com"><i class="fa fa-university"></i> Digital dissertation</a></nav>

<nav><a class="sidebar-nav-item" href="/tag/dissertation/"><i class="fa fa-pencil"></i>
 Dissertation blogging</a></nav>

<nav><a class="sidebar-nav-item" href="http://www.InfiniteUlysses.com"><i class="fa fa-book"></i>
 Infinite Ulysses</a></nav>
 
 <nav><a class="sidebar-nav-item" href="http://linkedin.com/in/amandavisconti"><i class="fa fa-linkedin"></i> LinkedIn</a></nav>

<nav><a class="sidebar-nav-item" href="http://www.twitter.com/Literature_Geek"><i class="fa fa-twitter"></i>
 Twitter</a></nav>

<nav><a class="sidebar-nav-item" href="https://github.com/amandavisconti"><i class="fa fa-github"></i>
 GitHub</a></nav>
 
<nav><em><a class="sidebar-nav-item" href="https://creativecommons.org/licenses/by-nc/2.0/">CC BY-NC by Dr. Amanda Visconti</a></em></nav>

</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/" title="Home">Literature Geek</a>
            <small>smarter online communities via digital humanities</small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2012/06/14/whats-up-with-digital-editing-tools-summer-conference-edition">
        What’s Up with Digital Editing Tools? (Summer Conference Edition)
      </a>
    </h1>








  <span class="post-date">By Amanda Visconti | 14 Jun 2012 | 
        
        

<a href="/tag/digital-humanities">digital humanities</a>,
      

<a href="/tag/textual-scholarship">textual scholarship</a>
      </span>

    <p>I’ve just returned from a whirlwind ten days of DH conferences. If I only paid attention to my mode of residence during the trip, I’d call this post “DH via Dorm Rooms”, but what I really got out of the experience (besides some serious college deja vu!) was a useful overview of what’s going on in the world of digital editing tools.</p>
<p><strong>Omeka for Textual Scholars.</strong> The first stop was the <a href="http://www.textual.org">Society for Textual Scholarship</a> (STS) conference in Austin, Texas, which while not purely a digital conference necessarily gravitated toward discussions of digital tools. I began the conference by teaching a workshop, “Zero to Archive in Sixty Seconds: An <a href="http://www.omeka.org">Omeka</a> Workshop for Textual Scholars” (teaching tools from the workshop are available <a href="http://digitalliterature.net/workshops/sts12.html">here</a>). Omeka is a powerful platform for creating digital museums--and if you’re interested in a non-traditional sort of digital literary edition, one that situates a text or texts in a rich discourse field of media related to its creation and reception, Omeka helps you realize a narrative out of an archive of interlinked media. There’s also growing work on plugins specific to creating a more traditional type of edition within Omeka, such as Scripto (transcription crowdsourcing), TEIDisplay plus SolrSearch (displays TEI files and makes them phrase-searchable), and the TEI Boilerplate (another method of TEI display), all of which we explored during the workshop.</p>
<p><strong>Teaching “Thinking Like an Editor”.</strong> Later at STS, I led a panel of editors from varied disciplinary backgrounds (theater performance, education, religion, Arabic language and translation, and digital edition design) in talking about ways to expose more people to “think like an editor”. Starting from Gary Taylor’s suggestion that the function of the editor is to help people get near texts and thereby love these cultural artifacts, we had a lively discussion about practical classroom assignments and digital tools for making our editions more participatory. One example of editing pedagogy we explored was MITH’s recent mentoring of graduate students in Neil Fraistat’s <a href="http://mith.umd.edu/eng738T/category/spring-2012/">Technoromanticism</a> course; by conceiving the <a href="http://www.shelleygodwinarchive.org">Shelley-Godwin Archive</a> as a teaching site, MITH was both able to bring students closer to a text they’d already come to care about (each student marked up ten pages of Mary Shelley’s <em>Frankenstein</em> manuscript with TEI) as well as teach some practical digital skills and workflows (captured in <a href="https://amandavisconti.github.io/markup-pedagogy/">this documentation</a>). In addition to introducing students to “thinking like an editor” around texts to which they already have some emotional connection, we discussed tactics for bringing historical textual artifacts alive such as exploring marginalia for evidence of a writer’s habits and thinking, exposing students to the materiality of old texts, and using performance to teach making editing decisions.</p>
<p><strong>An Evolving Digital Editions Platform.</strong> After STS, the next stop was the <a href="http://www.dhsi.org">Digital Humanities Summer Institute</a> (DHSI) in Victoria, British Columbia, where I took the Digital Editions course taught by <a href="http://www.matthuculak.com">Matt Huculak</a>. This course explored the evolving <a href="http://www.editingmodernism.ca">Editing Modernism in Canada</a> project platform <a href="http://www.modernistcommons.ca">Modernist Commons</a>, a tool that offered an interesting counterpoint to the edition options available with Omeka. Modernist Commons is being developed on <a href="http://islandora.ca">Islandora</a>, a hybrid of the <a href="http://www.drupal.org">Drupal</a> CMS and the <a href="http://www.fedora-commons.org">Fedora Commons</a> repository system; to put it simply, it’s a WYSIWYG tool for creating complete digital editions. The platform includes an ingest and OCR transcription process, areas for both TEI and RDF markup, rectangular and polygonal image annotation, and a shared collection of entity information (i.e. so that naming and events marked in different editions point to the same idea). The tool supports a number of front-end layouts such as the Internet Archive viewer, which allows a book-like appearance with pages that flip as you read, and also allows for the inclusion of born-digital content such as editorial methodologies. EMiC Project Director <a href="http://sinisterplots.wordpress.com">Dean Irvine</a> described the goals for Modernist Commons as offering both a platform for enriching text meaningfully without necessarily requiring knowledge of TEI (e.g. using simple RDF relationship fields and image annotation) as well as, for more advanced users, a platform that is modular and allows for customization and mass production of a variety of editions. It was fascinating to play around with a tool that was still in development and discuss the choices actively shaping it with its developers.</p>
<p><strong>DHSI and DH</strong>. Beyond the Digital Editions course, DHSI was a powerful demonstration of just how many fascinating areas of knowledge the umbrella “Digital Humanities” covers. With seventeen courses covering everything from physical computing (e.g. 3d printers) to digital pedagogy to the pre-digital book, a common theme among attendees was how difficult it had been to decide on just one of those classes to take (in fact, many attendees come back year after year from across the country to take more of DHSI’s course offerings). I was also impressed with how much the Digital Humanities community benefits <em>socially</em> from its allegiance to new technologies. Since everyone is always a novice when working with evolving tools, there’s extra impetus to help one another learn and generally geek and rejoice in the sharing of new knowledge and skills.</p>
<p>STS and DHSI provided a lovely ten days of sharing knowledge about the future of digital editing, and I’m looking forward to repeating the DHSI experience at MITH in January, when we host the first Digital Humanities Winter Institute.</p>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2012/04/19/ach-microgrant-award">
        Mapping the Flow of Knowledge with "View DHQ": ACH Microgrant Award
      </a>
    </h1>








  <span class="post-date">By Amanda Visconti | 19 Apr 2012 | 
        
        
        
        

<a href="/tag/digital-humanities">digital humanities</a>,
      

<a href="/tag/best">best</a>,
      

<a href="/tag/gephi">Gephi</a>,
      

<a href="/tag/scholarly-web-design-and-coding">scholarly web design and coding</a>
      </span>

    <p>I am one of four winners of the 2012 <a href="http://ach.org/2012/04/19/ach-announces-microgrants-winners/">Association for Computers and the Humanities (ACH) Microgrant</a>s awards! ACH Microgrants reward enterprising ideas that serve the digital humanities community; read more about the awards <a href="http://ach.org/2012/01/27/ach-microgrants/">here</a>, or read on for info on my funded project.</p>
<p id="internal-source-marker_0.5258509564762831">The digital humanities movement is often conceived as a community of practice, with defined networks such as the <em>Digital Humanities Now</em> Twitter list, <em>Digital Humanities Questions and Answers</em> forum, and various journals acting as platforms for sub-genres of DH research. <em>Digital Humanities Quarterly</em>, while a fairly recent journal, attracts more broadly relevant and interdisciplinary work than more focused fora such as <em>Digital Medievalist</em>; this breadth makes <em>DHQ</em> an excellent test case for tracking the flow of knowledge in the digital humanities via attention to the citation networks of its articles. Thisƒ application proposes a visualization of <em>DHQ</em>’s citation networks with an eye toward identifying key digital humanities texts.</p>
<p>DH is no stranger to citation network analysis. A 2009 <em>DHQ</em> article, Neel Smith’s “Citation in Classical Studies”, argued for citations as “descriptive of the subject of study”: “citation is a form of ontology: how we cite the objects we study identifies and describes the material of our domain independently of any technology” (<a href="http://www.digitalhumanities.org/dhq/vol/3/1/000028/000028.html">link</a>). Mapping of digital humanities articles across journals is not new (e.g. Salah, Leydesdorff, and Scharnhorst 2010, <a href="http://dh2010.cch.kcl.ac.uk/academic-programme/abstracts/papers/html/ab-673.html">link</a>), but the focus of such research has been on exploring which journals include DH work, not which individual DH works are cited within journals. Citation network research that includes information sources other than journal articles is not yet widespread in the digital humanities.</p>
<p>This ACH Microgrant will support making the existing <em>DHQ</em> citation content more visible and more easily analyzed through a visualization; the grant also allows MITH to provide code that could be used in future dynamic citation network visualization implementations. MITH Assistant Director Travis Brown assisted me in conducting preliminary investigations with <em>DHQ</em>’s citation data to ensure it is usable in my visualization tool of choice, <a href="http://www.gephi.org">Gephi</a>. For an example of Gephi used in DH network analysis research, check out <a href="http://dhs.stanford.edu/dh/gephi/dhstanford2.html">Elijah Meeks and Molly Wilson’s ongoing work using Gephi </a>to visualize self-reported digital humanities affiliation at Stanford; my final visualization should combine the visual appeal of Meeks and Wilson’s work with an easy way to drill down and view the individual works and citations involved in the network.</p>
<p>A key issue in my work will be the current size of the <em>DHQ</em> dataset (110 articles), a small amount of articles from which to draw conclusions. However, my visualization work remains useful because my focus is on mapping connections, not asserting significant authority for any individual author or work. Also, my visualization process can provide a foundation for ongoing citation network visualizations as <em>DHQ</em> continues to grow.</p>
<p>The final deliverables will be one or more visual files of the citation network visualizations, the code used to capture and clean the citation data for visualization, and a final report. The final report will both technical and conceptual, documenting my scraping and visualizing process and addressing future paths for network analysis with DHQ’s citation data.</p>
<p>Possibilities for future work include exploring the bibliographic details of what is cited (e.g. publishing format and venue, academic discipline and job title of author) as well as analyzing which academic fields are under-represented and which formats are mentioned within articles but not cited (as is sometimes the case with digital archives and academic blog posts). Linearity (who cites whom) and time elapsed between publication and citation are other interesting places for visualization and analysis. Additionally, I may be able to visualize a meaningful subset of <em>DHQ</em> articles citing other <em>DHQ</em> articles as the <em>DHQ</em> dataset grows. As I explore these possibilities for more detailed visualizations, I will articulate their proposed interpretations, keeping my emphasis on network exploration rather than asserting authority for any individual works or authors. The outcome of this work should stretch beyond these deliverables by offering <em>DHQ</em> a basis on which to eventually create a dynamically updated citation network visualization.</p>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2012/04/19/how-can-you-love-a-work-if-you-dont-know-it-six-lessons-from-team-markup">
        “How Can You Love a Work If You Don't Know It?”: Six Lessons on Digital Editing from Team MARKUP
      </a>
    </h1>








  <span class="post-date">By Amanda Visconti | 19 Apr 2012 | 
        
        
        
        

<a href="/tag/digital-humanities">digital humanities</a>,
      

<a href="/tag/textual-scholarship">textual scholarship</a>,
      

<a href="/tag/dh-now">featured on DH Now!</a>,
      

<a href="/tag/best">best</a>
      </span>

    <p><em>Team MARKUP evolved as a group project in Neil Fraistat's <a href="http://mith.umd.edu/eng738T/category/spring-2012/">Technoromanticism graduate seminar</a> (English 738T) during the Spring 2012 term at the University of Maryland; our team was augmented by several students in <a href="http://digital19thcentury.wordpress.com">the sister course</a> taught by Andrew Stauffer at the University of Virginia. The project involved using git and GitHub to manage a collaborative encoding project, practicing TEI and the use of the Oxygen XML editor for markup and validation, and encoding and quality-control checking nearly 100 pages of Mary Shelley's </em><em>Frankenstein</em> manuscript for the <a href="http://www.shelleygodwinarchive.org">Shelley-Godwin Archive</a> (each UMD student encoded ten pages, while the UVa students divided a ten-page chunk among themselves).</p>
<p>Team MARKUP wrote <a href="http://mith.umd.edu/eng738T/team-markup-encoding-frankenstein-for-the-shelley-godwin-archive-2/">a collaborative post</a> covering the different phases of the project in detail, so I’ll use this post to concentrate on some specifics of my personal experience with the project.</p>
<h2>Six takeaways from the Team MARKUP project:</h2>
<ol>
<li><strong>Affective editing is effective editing?</strong> One of my favorite quotations--so beloved that it shapes my professional work and has been reused shamelessly on my Ph.D. exams list, a Society for Textual Scholarship <a href="/2012/04/society-for-textual-scholarship-panel-abstract">panel abstract</a>, and at least one paper--is Gary Taylor’s reasoning on the meaningfulness of editing: “How can you love a work, if you don't know it? How can you know it, if you can't get near it? How can you get near it, without editors?”*. Encoding my editorial decisions with TEI pushed me a step closer to the text than my previous non-encoded editorial experience, something I didn’t know was possible.
<p><img alt="Screenshot of TEI for first page of volume ii of Frankenstein" src="/assets/TEIexample.jpg" width="550" height="122">The Creature speaks! TEI for the first page of the Creature's monologue in Shelley's Frankenstein.</p>
<p>My ten pages happened to be the first pages of the Creature’s monologue; hearing the voice of the Creature by seeing its true creator’s (Mary Shelley’s) handwriting gave me shivers--meaningful shivers accompanied by a greater understanding of important aspects of Shelley’s writing, such as the large editorial impact made by her husband Percy and the differing ways she crossed out or emphasized changes to her draft. Moving between the manuscripts images and the TEI encoding--so similar to my other work as a web designer and developer--also emphasized the differences in the writing process of my generation and the work that went into inscribing, organizing, and editing a book without the aid of a mechanical or digital device.</li>
<li><strong>Project management.</strong> Because we didn’t know what to expect from the project until we were in the thick of encoding--would everyone be able to correctly encode ten full pages? how would we control quality across our work? what would our finished pages look like in terms of encoding depth?--we spent most of the project functioning as a large team, which was both sometimes as unwieldy as our large GoogleDoc (trying to find a time when eight busy graduate students can meet outside of class time is difficult!) and sometimes made sense (I was one of the few people on our team comfortable with GitHub and encoding at the start of the project, so I helped with a lot of one-on-one Skype, in-person, and email sessions early on). If I did the project over, I would have held a single Bootcamp day where we all installed and pushed within GitHub and encoded one page of manuscript up on the projector screen, then delegated my role as team organizer by dividing us into three subgroups. I also might have insisted on people agreeing ahead of time on being available for specific in-person meeting times, rather than trying to schedule these one or two weeks beforehand. I do think things worked out pretty well as they did, largely because we had such a great team. Having the GoogleDoc (discussed more below) as a central point for tech how-tos, advice, and questions was also a good choice, though in a larger project I’d probably explore a multi-page option such as a wiki so that information was a) easier to navigate and b) easily made public at the end of our project.</li>
<li><strong>Changing schemas and encoding as interpretive.</strong> Encoders who started their work early realized that their efforts had good and bad results: because the schema saw frequent updates during our work, those who finished fast needed to repeatedly update their encoding (e.g. a major change was removing the use of <mod type>s). Of course it was frustrating to need to update work we thought was finished--but this was also a great lesson about work with a real digital edition. Not only did the schema changes get across that the schema was a dynamic response to the evolving methodology of the archive, it prepared us for work as encoders outside of a classroom assignment. Finally, seeing the schema as a dynamic entity up for discussion emphasized that even among more seasoned encoders, there are many ways to encode the same issue: encoding, as with all editing, is ultimately interpretative.</li>
<li><strong>Encode all the things! Or not.</strong>Depth of encoding was a difficult issue to understand early on; once we’d encoded a few pages, I began to have a better sense of what required encoding and what aspects of the manuscript images I could ignore. Initially, I was driven to encode everything, to model what I saw as thoroughly as possible: sums in the margins, different types of overstrikes, and analytical bibliography aspects such as smudges and burns and creases.
<p><img alt="x all the y meme stating encode all the things!" src="/assets/encode-300x215.jpg" width="300" height="215">Encode all the things... or not. Remixed from image by Allie Brosh of Hyperbole (hyperboleandahalf.blogspot.com).</p>
<p>What helped me begin to judge what to encode was understanding what was useful for Team MARKUP to encode (the basics that would apply to future encoding work: page structure and additions and deletions), what was useful for more advanced encoders to tackle (sitting in on the SGA staff meetings, I knew that some of our work would be subject to find-and-replace by people more experienced with Percy and Mary’s handwriting styles), and what our final audience would do with our XML (e.g. smudges and burns weren’t important, but Percy’s doodles could indicate an editorial state of mind useful to the literary scholar).</li>
<li><strong>Editorial pedagogy.</strong> Working on Team MARKUP not only improved my markup skills, it also gave me more experience with teaching various skills related to editions. As I mentioned above, acting as organizer and de facto tech person for the team gave me a chance to write up some documentation on using GitHub and Oxygen for encoding work. I’m developing this content for <a href="https://amandavisconti.github.io/markup-pedagogy/">this set of GitHub Pages</a> to help other new encoders work with the Shelley-Godwin Archive and other encoding projects. Happily, I was already scheduled to talk about editorial pedagogy at two conferences right after this seminar ends; the Team MARKUP experience will definitely become part of my talks during <a href="/2012/04/society-for-textual-scholarship-panel-abstract">a panel</a> I organized on embedding editorial pedagogy in editions (Society for Textual Scholarship conference).</li>
<li><strong>Ideas for future encoding work.</strong> I’ve started to think about ways to encode Frankenstein more deeply; this thinking has taken the form of considering tags that would let me ask questions about the thematics of the manuscript using Python or <a href="http://voyeurtools.org/tool/Links/">TextVoyeur</a> (aka Voyant); I’m also interested in markup that deals with the analytical bibliography aspects of the text, but need to spend more time with the rest of the manuscript images before I think about those. So far, I’ve come up with five new thematic tagging areas I might explore:</li>
</ol>
<ul>
<li><strong>Attitudes toward monstrosity:</strong> A tag that would identify the constellation of related words (monster, monstrous, monstrosity), any mentions of mythical supernatural creatures, metaphorical references to monstrosity (e.g. “his vampiric behavior sucks the energy out of you”), and reactions/attitudes toward the monstrous (with attributes differentiating responses to confronting monstrosity with positive, negative, and neutral attitudes). I could then track these variables as they appear across the novel and look for patterns (e.g. do we see less metaphorical references to monstrosity once a “real” monster is more prevalent in the plot?).</li>
<li><strong>Thinking about doodles:</strong> We’re currently marking marginalia doodles with <figure> and a <desc> tag describing the drawing. In our section of the manuscript, many (all?) of these doodles are Percy Shelley’s; I’d like to expand this tag to let me identify and sort these doodles by variables such as complexity (how much thought went into them rather than editing the adjacent text?), sense (do they illustrate the adjacent text?), and commentary (as an extension of sense tagging, does a doodle seem ironically comic given the seriousness or tragedy of the adjacent text?). For someone new to studying Percy’s editorial role, such tagging would help me understand both his editing process and his attitude toward Mary’s writing (reverent? patronizing? distracted? meditative?)</li>
<li><strong>Names, dates, places:</strong> These tags would let us create an animated timeline of the novel that shows major characters as they move across a map.</li>
<li><strong>Anatomy, whole and in part:</strong> To quote from an idea raised in <a href="http://mith.umd.edu/eng738T/useful-prosthetics-pretty-metaphors-and-more-on-dh-tools/">an earlier post</a> of mine, I’d add tags that allowed “tracking the incidence of references to different body parts–face, arms, eyes–throughout Frankenstein, and trying to make sense of how these different terms were distributed throughout the novel. In a book concerned with the manufacture of bodies, would a distant reading show us that the placement of references to parts of the body reflected any deeper meanings, e.g. might we see more references to certain areas of the body grouped in areas of the novel with corresponding emphases on the display, observation, and action? A correlation in the frequency and placement of anatomical terms with Frankenstein‘s narrative structure felt unlikely (so unlikely that I haven’t run my test yet, and I’m not saving the idea for a paper!), but if had been lurking in Shelley’s writing choices, TextVoyeur would have made such a technique more visible.”</li>
<li><strong>Narrative frames:</strong> Tags that identified both the specifics of a current frame (who is the speaker, who is their audience, where are they, how removed in time are they from the events they narrate?) and that frame’s relationship to other frames in the novel (should we be thinking of these words as both narrated by Walton and edited by Victor?) would help create a visualization of the novel’s structure.</li>
</ul>
<p>I expect that playing around with such tags and a distant reading tool would yield even better thinking about encoding methodology than the structural encoding I’ve been working on so far, as the decisions on when to use these tags would be so much more subjective.</p>
<p>* <em>From "The Renaissance and the End of Editing", in Palimpsest: Textual Theory and the Humanities, ed. George Bornstein and Ralph G. Williams (1993), 121-50.</em></p>
  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="/page22">Older Posts</a>
  
  
    
      <a class="pagination-item newer" href="/page20">Newer Posts</a>
    
  
</div>


      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', function(e) {
          var target = e.target;

          if(!checkbox.checked ||
             sidebar.contains(target) ||
             (target === checkbox || target === toggle)) return;

          checkbox.checked = false;
        }, false);
      })(document);
    </script>
  </body>
</html>
